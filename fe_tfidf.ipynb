{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 41s, sys: 29.4 s, total: 11min 10s\n",
      "Wall time: 11min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords \n",
    "import pickle\n",
    "from scipy import sparse\n",
    "from nltk.tokenize.toktok import ToktokTokenizer \n",
    "from nltk.stem.snowball import RussianStemmer\n",
    "from nltk import sent_tokenize # should be multilingual\n",
    "from string import punctuation\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import FastText\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "punct = set(punctuation)  \n",
    "\n",
    "# load data\n",
    "df_text = pickle.load(open('./data/df_text.pkl','rb'))\n",
    "\n",
    "# Tf-Idf\n",
    "def clean_text(s):\n",
    "    s = re.sub('м²|\\d+\\\\/\\d|\\d+-к|\\d+к', ' ', s.lower())\n",
    "    s = re.sub('\\\\s+', ' ', s)\n",
    "    s = s.strip()\n",
    "    return s   \n",
    "    \n",
    "russian_stop = set(stopwords.words('russian'))\n",
    "\n",
    "df_text['param_123'] = df_text['param_123'].apply(lambda x: clean_text(x))\n",
    "df_text['title'] = df_text['title'].apply(lambda x: clean_text(x))\n",
    "df_text[\"text\"] = df_text[\"text\"].apply(lambda x: clean_text(x))\n",
    "\n",
    "df_train_text = df_text[df_text['deal_probability'].notnull()]\n",
    "df_test_text = df_text[df_text['deal_probability'].isnull()]\n",
    "\n",
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"lowercase\": True,\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "vectorizer = FeatureUnion([\n",
    "        ('text',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=200000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('text'))),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words = russian_stop,\n",
    "            preprocessor=get_col('title'))),\n",
    "        ('param_123',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            stop_words = russian_stop,\n",
    "            preprocessor=get_col('param_123')))    \n",
    "    ])  \n",
    "\n",
    "vectorizer.fit(df_text.to_dict('records'))\n",
    "ready_df_train = vectorizer.transform(df_train_text.to_dict('records'))\n",
    "ready_df_test = vectorizer.transform(df_test_text.to_dict('records'))\n",
    "tfvocab = vectorizer.get_feature_names()\n",
    "\n",
    "sparse.save_npz('./data/features/nlp/ready_df_train_200000_new.npz', ready_df_train)\n",
    "sparse.save_npz('./data/features/nlp/ready_df_test_200000_new.npz', ready_df_test)\n",
    "\n",
    "with open('./data/features/nlp/tfvocab_200000_new.pkl', 'wb') as tfvocabfile:  \n",
    "    pickle.dump(tfvocab, tfvocabfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
